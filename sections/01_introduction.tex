\section{Introduction}
\label{sec:introduction}

\textit{Conformance checking} is a branch of process mining assessing whether a sequence of distinguishable events (i.e., a \textit{trace}) conforms to the expected process behavior represented as a \textit{process model} \cite{RozinatA08}. When a trace does not conform to the model, we say that the trace is \textit{deviant}. In this case, techniques based on cost-driven alignments additionally provide minimal repair strategies to make the trace conformant to the model \cite{DBLP:conf/edoc/AdriansyahDA11}. Alignments represent a valuable instrument for business analysts, as the combined provision of alternative repair strategies, ranked by alignment cost, supports the business analyst in choosing among different process improvement strategies. In conformance checking, models can be described by either procedural or declarative languages;  while the former fully enumerate the set of all the possible allowed traces, the latter %\deleted{provide a compact process representation by}
list the constraints delimiting the expected behavior. %Nevertheless, %\deleted{LTL$_f$-based}
\added{Declarative process models like Declare models \cite{DBLP:conf/edoc/PesicSA07}, whose semantics can be expressed in \added{Linear Time Logic on finite traces (LTL$_f$)} \cite{GiacomoV13} can always be transformed into constraint automata.}
%\added{As LTL$_f$ is an extension of modal logic in which worlds are organized in an finite linear structure, this logic is well suited to describe business processes logs having traces of finite length \cite{GiacomoV13}.}
%
%In fact, such semantics describes the actions that will follow when some pre-conditions are met \cite{LiPZVR20}.
The representation of Declare models as automata can be adopted for aligning traces with this type of models \cite{LeoniMA12,XuLZ17a}.
\\
\indent
Multi-perspective checking for process conformance is gaining momentum, as conformance checking techniques considering both trace types and data annotations as ``first-class citizens'' enable to discover more deviations \cite{MultiPerspective}. This reflects the essence of real-world business processes, which are inherently described by both processes and their different domain objects \cite{PetermannJMR14} (e.g., employees, products, etc.), which can be encoded as traces and event data. While alignment-based  data-aware conformance has been already investigated in the context of procedural models, most of the conformance checking approaches for data-aware declarative models \cite{BurattinMS16,Borrego014} focus on a numerical approximation of the degree of conformance of a trace against the model and do not provide repair strategies.
\\
\indent
To tackle this research gap, we propose a novel approach for aligning event logs to data-aware declarative models by reducing it to a data-agnostic alignment problem over LTL$_f$-based models. This solution exploits the following considerations: \begin{enumerate*}[label=\emph{\alph*})]
	\item \label{it1} to represent the process model, we use a sub-set of the data-aware extension of Declare presented in \cite{BurattinMS16}. After representing the data-aware Declare model using a data\added{-}agnostic LTL$_f$ semantics,
	\item \label{it2} we exploit the data predicates in the data-aware Declare clauses to partition the data space. This provides propositions representing data in addition to event labels. Then,
	\item we combine each event label with the propositions generated in \ref{it2} and transform the model in \ref{it1} into its data-aware counterpart. The automata-based representation of such a model is used to align traces (seen as sequences of events with a payload of data attribute-value pairs) with the model.
In particular, we show that the alignment problem can be expressed as a planning problem in Artificial Intelligence, which can be efficiently solved by selected state-of-the-art planners \cite{XuLZ17a,Marrella17}.
%
\\
\indent
\added{Despite the resulting data-agnostic alignment via planning is semantically equivalent to customary cost-based aligners \cite{DBLP:conf/edoc/AdriansyahDA11}, our previous work \cite{XuLZ17a} showed that the former outperforms the latter in terms of computational performance and scalability in the presence of models of considerable size, which is the case of this paper. In fact, as a consequence of the reduction of the data-aware alignment problem into a data-agnostic one, the automata-based process models used as input for our approach have several more transitions and states than in traditional alignment problems. Therefore, as we needed to show the feasibility of our approach, we decided to resort to planning-based alignments for both presenting our framework outline and performing the experiments.}
%
%\added{According to our previous works, \cite{XuLZ17a,LeoniM17} already remarked that such algorithms outperform state-of-the-art trace alignment algorithms where data payload is not considered} .
%
\added{Planners generate} repair strategies able to align traces with a data-aware declarative model based on changes at the level of control flow (such as adding/deleting events) or at the level of the data flow (such as changing the attribute values attached to them).
\end{enumerate*}

%The rest of the paper is structured as follows: after providing relevant related works (\S\ref{sec:related}), we introduce the notion of event log (\S\ref{ssec:elog}) and the data-aware declarative language used to represent the model (\S\ref{ssec:dad}); we also provide hints on Automated Planning, as we will later exploit the SymBA*-2 optimal planner \cite{torralba2014symba} to compute the alignments (\S\ref{ssec:ap}). These preliminary notions guide us into the definition of our  working assumptions adhering to the literature of reference (\S\ref{sec:wa}). After deep-diving into the technical details providing the solution to the data-aware declarative alignment problem (\S\ref{sec:dccap}), we benchmark SymBA*-2 over a synthetic dataset and discuss its performance in this context (\S\ref{sec:experiments}). Last, we draw our final conclusions and propose some future work (\S\ref{sec:end}).


%we draw the working assumptions jointly with the assumptions from the current literature on declarative conformance checking (\S\ref{sec:wa}). After outlining the declarative model alignment over which we want to reduce the problem (\S\ref{sec:dccap}), we deep-dive into the data-aware Declare Trace Alignment Pipeline (\S\ref{sec:dadtap}) \texttt{\color{red} [TODO: experiments? ]} Last, we draw our final conclusions and propose some future works (\S\texttt{\color{red}[TODO]}).
