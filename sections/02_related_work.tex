\section{Related Work}
\label{sec:related}

Most of the conformance checking techniques reported in the scientific literature are based on procedural models. In \cite{DBLP:conf/edoc/AdriansyahDA11}, for the first time, the authors introduce conformance checking augmented with the notion of alignments.
%Similarly, data perspective for con\-form\-ance checking with Declare could be expressed in terms of conditions on global process variables disconnected from the specific Declare constraints expressing the control flow \cite{Borrego014}.  As pointed out in \cite{MultiPerspective}, such solution provides misleading results, as often control-flow and data prospective are closely inter-related in real-world scenarios models \cite{PetermannJMR14}. As a result, a cost function considering both data and control-flow discrepancies is required. Still, it is widely known \cite{AdriansyahDA10} that some trace-alignment strategies do not provide correctness guarantees, as perfectly fitting traces might be assessed as non-fitting executions.
A multi-perspective alignment-based approach has been presented in \cite{MultiPerspective}, where the authors propose techniques for conformance checking with respect to data-aware procedural models. \added{This work combines the A* algorithm for alignment-based control-flow conformance checking with Integer Linear Programming for data conformance checking.}
\\
\indent
\added{The work described in \cite{LeoniMA12} presents a (data-agnostic) conformance checking approach based on the concept of alignment for declarative models. It consists in converting a Declare model into an automaton and perform conformance checking of a log with respect to the generated automaton. The conformance checking approach is based on the concept of alignment and as a result of the analysis each trace is converted into the most similar trace that the model accepts. This approach is similar to the procedural one presented in \cite{MultiPerspective}. Our first attempt was, therefore,} to extend this data-aware procedural approach to the declarative case. However, since this approach first processes the control flow and then tests data conditions, it cannot be easily applied to data-aware Declare. Indeed, in case the reference model contains constraints that are in conflict when considering the control flow in isolation (e.g., constraints requiring the existence and the absence of the same activity $\texttt{payment}$) this approach would stop after the first step because it cannot find any control flow-based alignment given the inconsistency of the model. \added{It has been also proved that such a solution does not correctly handle the situation when (e.g.,)} $\texttt{payment}$ is forbidden with a negative amount but must occur with a positive amount. This issue could prevent this approach from finding alignments that, instead, could be found when considering control flow and data in combination in the reference model.
%\added{\cite{LeoniA13} combines the A* algorithm for alignment-based control-flow conformance checking with Integer Linear Programming for data conformance checking. }
%The work described in \citep{Leoni2012,DeLeoni2014}
\\
\indent
\added{More recently, in \cite{Borrego014}, the authors have presented an approach where the data perspective for conformance checking with Declare is expressed in terms of conditions on global process variables disconnected from the specific Declare constraints expressing the control flow. In other words, data constraints are not bound to control flow constraints and thus it is not possible to bind the behavior to specific data attributes. The only truly multi-perspective approach based on declarative models is the one presented in \cite{BurattinMS16}. Here, the authors provide an algorithmic framework to efficiently check the conformance of individual data-aware Declare constraints with respect to event logs. However, this approach has been developed to provide scalable algorithms that quickly check if a trace (seen as a string) is compliant or not with respect to every constraint in the input model separately. The algorithms of the framework are \emph{ad hoc} in the sense that each of them is tailored to a specific type of temporal rule to be checked and the semantics of each temporal rule is embedded in the algorithm itself. To compute alignments with respect to a Declare model as a whole, an algorithm expressing the semantics of the conjunction of  each possible combination of (data-aware) constraints should be developed. This is clearly a difficult and error-prone task that needs more advanced instruments to be addressed. This is why we rely on automata-theory and Automated Planning to solve it.}  \added{Furthermore, despite both approaches provide a numerical characterization of the degree of conformance of a log trace against the model, no repair strategy is given. As we will observe in \S\ref{sec:dadtap}, the possibility of repairing traces is related with the definition of strings and numerical data as elements of a partially ordered set, where missing values are the minimal elements of such a set. Furthermore, our work extends the previous ones by also considering string data as well as numerical data.}

%\added{In this work, the authors reduce the data-aware conformance checking problem to a maximum constraint-satisfaction problem, where both data and model constraints are encoded. Alternatively, the alignment of data-aware declarative processes can be also reduced to a constraint satisfaction problem, where an optimization function is used to assess the alignment cost \cite{Borrego014}.  The two aforementioned works are, to the best of our knowledge, the only ones providing numerical characterization of the process conformance for declarative models.  Even though they provide a numerical approximation of the degree of conformance of a log trace against the model, no repair strategy is given. As we will observe in \S\ref{sec:dadtap}, the possibility of repairing traces is related with the definition of strings and numerical data as elements of a partially ordered set, where missing values are the minimal elements of such a set. Furthermore, our work extends the previous ones by also considering string data as well as numerical data.} 